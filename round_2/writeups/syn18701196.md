# AI Winter is Coming

Mariya Popova<sup>1</sup>,  Stephen Capuzzi<sup>1,2</sup>,  Olexandr Isayev<sup>1,*</sup>
(1) UNC Eshelman School of Pharmacy,  University of North Carolina at Chapel Hill, NC 27516
(2) Currently at Vertex Pharmaceuticals,  Boston, MA
\* Corresponding author; email: olexandr@olexandrisayev.com

## Methods
To comply with challenge requirements about data/code availability, our final solution for Round 2 had to implement several shortcuts. We had to limit the dependence on commercial software/services as much as possible. Overall, this negatively affected most models vs. internal benchmarks. Therefore:
* Only RDKit fingerprints were used as a molecular representation. No other descriptors were used.
* Only one ML method was used - Gradient Boosted Decision Trees (GBDT) as implemented in XGBoost.
* Hyperparameter search was performed with a randomized search only. No custom GP or AutoML-like schemes were used.
* For simplicity, no model stacking was used.

Note, because of very large HPC compute demands our final prediction for MTOR, KDR, PLK1, SYK, TEK was done not with all 5 ensemble models, as they were not finished by the deadline.  This Docker has all finished model and produces slightly different predictions for these kinases. This difference, however, does not affect any rankings.

### Data
For all targets of interest, data was integrated from DrugTargetCommons and ChEMBL 25. Bioactivities were extracted for pChEMBL activity values -Log(IC50/EC50/Ki/Kd) of 10 μM or better, with ChEMBL CONFIDENCE_SCORE of 6 or greater for ‘binding’ or ‘functional’ human kinase protein assays. Due to conflicting naming schemes, all target datasets were integrated by Uniprot IDs. Each target dataset was curated according to our well-established best practices [J. Chem. Inf. Model.2010, 50 (7), 1189-1204  (https://doi.org/10.1021/ci100176x)]. Structural standardization, the cleaning of salts, and the removal of mixtures, inorganics, and organometallics was performed using ChemAxon software. In the case of replicate compounds, InChI Keys were generated. For replicates with the same activities in a given assay, a single representative compound was selected for inclusion into the training set. For replicates with the different activities (> 1 log unit) in a given assay, all compounds were excluded.

### Feature Representation
An ensemble of four RDKit fingerprints of path length 5,7,9,11; each of 4K bit length. The total length of the feature vector was 16K.

### Model Training.
All models were trained within two nested five-fold cross-validation loops. All splits were random.
Internal CV loop was used to perform hyperparameters search and variable selection for the corresponding fold using the following protocol:
1.	Fast XGBoost hyperparameter search with a budget of 100. The following parameters were tuned: max_depth, subsample, colsample_bytree, learning_rate, min_child_weight, gamma. n_estimators was fixed at 1000. For XGBoost we used fast histogram method on GPU and optimize for “log cosh” loss in order to reduce the effect of outliers.
2.	Using the optimal model we performed recursive feature elimination as implemented in Scikit-Learn (RFECV function).  A number of features that give model with the best MAE were selected.
3.	Rebuild XGBoost model with the optimal number of features and perform an additional hyperparameter search with a budget of 500. The following parameters were tuned: n_estimators, max_depth, subsample, colsample_bytree, colsample_bylevel, learning_rate, min_child_weight, gamma, reg_alpha, reg_lambda. For XGBoost we used fast histogram method on GPU and optimize for “log cosh” loss in order to reduce the effect of outliers.

Final scoring was done by averaging five predictions from the external CV loop.  Negative model bias was adjusted by scaling prediction values to the range of [5, prediction max]

## Conclusion
This is the winning solution for RMSE metric.

## Running the Docker Container

In order to run this Docker container, first pull the image using:  ```docker pull docker.synapse.org/syn18701196:9686282```

Then, from a local directory containing an "input" and "output" directory, where "input" contains the file "input.csv" (the round_2_template.csv from IDG-DREAM or similarly formatted file), run the following command: ```docker run -it --rm -v ${PWD}/input:/input -v ${PWD}/output:/output docker.synapse.org/syn18701196:9686282```
