---
title: "IDG-DREAM Round 2 Ensemble Analysis"
output:
  html_document:
    toc: true
    toc_float: true
date: "`r format(Sys.time(), '%d %B, %Y')`"
---

Round 2 of the IDG-DREAM Challenge gave participants two opportunities to predict 394 Kd values between 25 compounds and 207 kinases. 


First, import packages, scoring functions, and challenge data. 
```{r echo=FALSE, message=FALSE, warning=FALSE}
library(challengescoring)
library(reticulate)
library(tidyverse)
library(doMC)
doMC::registerDoMC(cores = detectCores()-1)

use_python("/usr/local/bin/python2")
synapse <- import("synapseclient")
syn <- synapse$Synapse()
synutils <- synapse$utils
syn$login()
source_python('https://raw.githubusercontent.com/Sage-Bionetworks/IDG-DREAM-Drug-Kinase-Challenge/master/round1b/score/bin/evaluation_metrics_python2.py')

spearman_py <- function(gold, pred){
  gold_py <- gold %>% np_array()
  pred_py <- pred %>% np_array()
  spearman(gold_py, pred_py)
}
    
rmse_py <- function(gold, pred){
   gold_py <- gold %>% np_array()
   pred_py <- pred %>% np_array()
   rmse(gold_py, pred_py)
}

auc_py <- function(gold, pred){
   gold_py <- gold %>% np_array()
   pred_py <- pred %>% np_array()
   average_AUC(gold_py, pred_py)
}


fv <- syn$tableQuery("select id, submissionId AS objectId, teamId, userId from syn18513076")$filepath %>%
  read_csv()

leaderboard <- read_csv(syn$get("syn18520916")$path) %>% full_join(fv)

get_path <- function(id){
  syn$get(id)$path
}

gold <- read_csv(syn$get("syn18421225")$path)

submitted_docker_and_methods <- c("3379336", #baseline
                                  "3361565", #n121
                                  "3378762", #KinaseHunter
                                  "3379046", #Kermit-lab
                                  "3377646", #QED
                                  "3379110", #KKT
                                  "3379198", #let data talk
                                  "3383197", #davor orsolic/prospectors
                                  "3380669", #boun
                                  "3380843", #druginaselearning
                                  "2223251", #mehmet tan, oselot
                                  "3361766", #thinng
                                  "3384382", #dmisdk
                                  "3371544", #metu_embl
                                  "3324878", #hulab
                                  "3337435", #aydin
                                  "3332429", #ai winter is coming
                                  "3380028", #ml med
                                  "3380320", #amsterdamumc-ku
                                  "3343575") #MCIC


get_user_or_team_names <- function(id){
 name <- try(syn$getTeam(id)$name, silent = T) ##try to get the team name from id 
 if(class(name)=='try-error'){ ##if it is not a team, will return error, so then try to get user profile
 try({
   prof <- syn$getUserProfile(id = id) ##get first and last name
   fn <- prof$firstName
   ln <- prof$lastName
   if(is.null(fn) | is.null(ln)){
     un <- prof$userName
     return(un) 
   }else if(fn == "" | ln == ""){ ##if empty, get username instead
     un <- prof$userName
     return(un)
   }else{
     return(paste(fn, ln))
   }
   })
   }else{
     return(name)
   }
}

names<- sapply(unique(leaderboard$submitterId), get_user_or_team_names)
names(names) <- unique(leaderboard$submitterId)
names_df <- as.data.frame(names) %>% 
  magrittr::set_colnames("participant") %>% 
  rownames_to_column("submitterId") %>% 
  mutate(submitterId= as.numeric(submitterId)) %>% 
  mutate(participant = as.character(participant))

names_df$participant[names_df$participant=="瑞 张"] <- syn$getUserProfile(id = names_df$submitterId[names_df$participant=="瑞 张"])$userName

names_df$participant[names_df$submitterId=="3383197"] <- "Prospectors"

# names_df$participant <- stringr::str_wrap(names_df$participant, width = 100)

```

#Spearman ensemble


Let's rank the submissions, taking the best submission from R2 for each team (54 submissions total, then).

```{r echo=TRUE, message=FALSE, warning=FALSE}

best_spearman_by_team <- leaderboard %>%
  group_by(submitterId) %>%
  top_n(1, spearman) %>%
  ungroup() %>%
  arrange(-spearman) %>%
  add_column(rank = group_indices(., -spearman)) %>% 
  mutate(objectId = as.character(objectId))  

paths <- map_chr(best_spearman_by_team$id, get_path)
names(paths) <- best_spearman_by_team$objectId

```

Then we map all of these ranked prediction files and gather the prediction values into one tidy data frame. 

```{r echo=TRUE, message=FALSE, warning=FALSE}
preds <- pmap(.l = list(path = paths, renameColname = 'pKd_[M]_pred', newName = names(paths)), .f = challengescoring:::.read_and_rename) %>%
  purrr::reduce(left_join) %>%
  tidyr::gather(objectId, pred, -Compound_SMILES, -Compound_InchiKeys, -Compound_Name, -UniProt_Id, -Entrez_Gene_Symbol, -DiscoveRx_Gene_Symbol) %>% 
  left_join(select(best_spearman_by_team, objectId, rank))

```

Then, we run apply across the number of ranks (1:54), and  iterate over each rank, filtering the data for that rank or better, grouping by each compound-kinase pair, and summarizing the prediction by taking the median prediction for each compound-kinase pair. We repeat this for each rank, and then reduce to get a data frame where median_ensemble_1 is the median predictions for rank 1, median_ensemble_2 is the median prediction for each compound-kinase pair for ranks 1:2, and so forth through 1:54. 

```{r echo=TRUE, message=FALSE, warning=FALSE}

median_preds_sp <- lapply(unique(preds$rank), function(i){
   colname <- paste0('spearman_median_ensemble_',i)
   foo <- preds %>%
     filter(rank <= i) %>% 
     group_by(Compound_SMILES, Compound_InchiKeys, Compound_Name, UniProt_Id, Entrez_Gene_Symbol,
              DiscoveRx_Gene_Symbol) %>% 
     summarize(!!colname := median(pred)) %>% 
     ungroup()
   foo
 }) %>% reduce(left_join)

```

Now, we need to figure out which ensemble is the best of the 54 we created. 

```{r echo=TRUE, message=FALSE, warning=FALSE}

median_test <- left_join(median_preds_sp, gold)

median_results_spearman <- apply(median_test %>% select(7:(ncol(median_test)-1),`pKd_[M]`), 2, spearman_py, 
                                 gold = median_test$`pKd_[M]`) %>% 
  as.data.frame() %>% 
  rownames_to_column("ensemble_model") %>% 
  filter(ensemble_model != "pKd_[M]") %>% 
  mutate(iteration = str_extract(ensemble_model, "[:digit:]+")) %>% 
  mutate(ensemble_model = str_extract(ensemble_model, "[:alpha:]+_[:alpha:]+_[:alpha:]+"))

```

Looks like the absolute best is median_ensemble_4.

Let's try some other aggregation methods: 

ranked (weighted mean) spearman:

```{r echo=TRUE, message=FALSE, warning=FALSE}

rank_preds_sp <- lapply(unique(preds$rank), function(i){
   colname <- paste0('spearman_rank_ensemble_',i)
   foo <- preds %>%
     filter(rank <= i) %>% 
     mutate(predrankweight = (pred*(55-rank))/sum((55-i):54)) %>% 
     group_by(Compound_SMILES, Compound_InchiKeys, Compound_Name, UniProt_Id, Entrez_Gene_Symbol,
              DiscoveRx_Gene_Symbol) %>% 
     summarize(!!colname := sum(predrankweight)) %>% 
     ungroup()
   foo
 }) %>% reduce(left_join)

rank_test <- left_join(rank_preds_sp, gold)

rank_results_spearman <- apply(rank_test %>% select(7:(ncol(rank_test)-1),`pKd_[M]`), 2, spearman_py, 
                                 gold = rank_test$`pKd_[M]`) %>% 
  as.data.frame() %>% 
  rownames_to_column("ensemble_model") %>% 
  filter(ensemble_model != "pKd_[M]") %>% 
  mutate(iteration = str_extract(ensemble_model, "[:digit:]+")) %>% 
  mutate(ensemble_model = str_extract(ensemble_model, "[:alpha:]+_[:alpha:]+_[:alpha:]+"))


```

mean:

```{r echo=TRUE, message=FALSE, warning=FALSE}

mean_preds_sp <- lapply(unique(preds$rank), function(i){
   colname <- paste0('spearman_mean_ensemble_',i)
   foo <- preds %>%
     filter(rank <= i) %>% 
     group_by(Compound_SMILES, Compound_InchiKeys, Compound_Name, UniProt_Id, Entrez_Gene_Symbol,
              DiscoveRx_Gene_Symbol) %>% 
     summarize(!!colname := mean(pred)) %>% 
     ungroup()
   foo
 }) %>% reduce(left_join)

mean_test <- left_join(mean_preds_sp, gold)

mean_results_spearman <- apply(mean_test %>% select(7:(ncol(mean_test)-1),`pKd_[M]`), 2, spearman_py, 
                                 gold = mean_test$`pKd_[M]`) %>% 
  as.data.frame() %>% 
  rownames_to_column("ensemble_model") %>% 
  filter(ensemble_model != "pKd_[M]") %>% 
  mutate(iteration = str_extract(ensemble_model, "[:digit:]+")) %>% 
  mutate(ensemble_model = str_extract(ensemble_model, "[:alpha:]+_[:alpha:]+_[:alpha:]+"))

```

calculate rmse for the mean ensemble for paper 

```{r echo=TRUE, message=FALSE, warning=FALSE}

mean_preds_rm_paper <- lapply(unique(preds$rank), function(i){
   colname <- paste0('rmse_mean_ensemble_',i)
   foo <- preds %>%
     filter(rank <= i) %>% 
     group_by(Compound_SMILES, Compound_InchiKeys, Compound_Name, UniProt_Id, Entrez_Gene_Symbol,
              DiscoveRx_Gene_Symbol) %>% 
     summarize(!!colname := mean(pred)) %>% 
     ungroup()
   foo
 }) %>% reduce(left_join)

mean_test <- left_join(mean_preds_rm_paper, gold)

mean_results_rmse_paper <- apply(mean_test %>% select(7:(ncol(mean_test)-1),`pKd_[M]`), 2, rmse_py, 
                                 gold = mean_test$`pKd_[M]`) %>% 
  as.data.frame() %>% 
  rownames_to_column("ensemble_model") %>% 
  filter(ensemble_model != "pKd_[M]") %>% 
  mutate(iteration = str_extract(ensemble_model, "[:digit:]+")) %>% 
  mutate(ensemble_model = str_extract(ensemble_model, "[:alpha:]+_[:alpha:]+_[:alpha:]+"))


```

Now stick them all together into one data frame and plot them to get an idea of relative performance. 

```{r echo=TRUE, message=FALSE, warning=FALSE}

ensemble_scores <- bind_rows(median_results_spearman, mean_results_spearman, rank_results_spearman, mean_results_rmse_paper)  %>%  
  set_names(c("ensemble_model", "score", "iteration")) %>% 
  mutate(iteration = as.numeric(iteration)) %>% 
  mutate(label = case_when(iteration == 1 & ensemble_model == "spearman_mean_ensemble"  ~ "Q.E.D.",
                           iteration == 2 & ensemble_model == "spearman_mean_ensemble"  ~ "1 + Gregory Koytiger",
                           iteration == 3 & ensemble_model == "spearman_mean_ensemble" ~ "2 + AI Winter is Coming",
                           iteration == 4 & ensemble_model == "spearman_mean_ensemble" ~ "3 + Oliver Labayle", 
                           iteration > 4 | ensemble_model != "spearman_mean_ensemble" ~ ""))

```

Cutoff any scores <0.45

```{r}
ggplot(data = ensemble_scores %>% 
         filter(grepl("*spearman*", ensemble_model)) %>% 
         filter(score > 0.45)) +
  geom_line(aes(x= iteration, y = score, color = ensemble_model)) +
  ggrepel::geom_label_repel(aes(x= iteration, y = score, label = label), nudge_x = 10, size = 3, segment.alpha = 0.25, arrow = grid::arrow(type = "open", length = unit(0.5, "lines")), alpha = 1, force = 100) +
  scale_color_manual(values = c("#AA1155","#F8333C","#2B9EB3"),
                     name = "Method",
                     labels = c("Mean", "Median", "Rank-weighted")) +
  theme_bw() +
  labs(x = "# of Models", y = "Spearman Correlation") +
  theme(axis.text = element_text(size = 12))

```



Include all scores 

```{r}
ggplot(data = ensemble_scores %>% 
         filter(grepl("*spearman*", ensemble_model)))  +
  geom_line(aes(x= iteration, y = score, color = ensemble_model)) +
  scale_color_manual(values = c("#AA1155","#F8333C","#2B9EB3"),
                     name = "Method",
                     labels = c("Mean", "Median", "Rank-weighted")) +
  theme_bw() +
  labs(x = "# of Models", y = "Spearman Correlation") +
  theme(axis.text = element_text(size = 12))
```


main paper figure

Cutoff any scores <0.45

spearman and RMSE for same model

```{r}

ensemble_scores_pap <- bind_rows( mean_results_spearman,mean_results_rmse_paper)  %>%  
  set_names(c("ensemble_model", "score", "iteration")) %>% 
  mutate(iteration = as.numeric(iteration)) %>% 
  mutate(label = case_when(iteration == 1  ~ "Q.E.D.",
                           iteration == 2  ~ "1 + Gregory Koytiger",
                           iteration == 3  ~ "2 + AI Winter is Coming",
                           iteration == 4  ~ "3 + Oliver Labayle", 
                           iteration > 4 ~ NA_character_)) %>% 
  mutate(ensemble_model_type = case_when(grepl("*spearman*", ensemble_model) ~ "Spearman",
                           grepl("*rmse*", ensemble_model)  ~ "RMSE"))

scal_fact <- 1.6

ggplot(data = ensemble_scores_pap %>% 
         filter(grepl("*spearman_mean*", ensemble_model)) %>% 
         filter(score > 0.45))+
  geom_line(data = ensemble_scores_pap %>% 
         filter(grepl("*rmse_mean*", ensemble_model)) %>% 
         filter(score <2),
         aes(x= iteration, y = score/scal_fact, linetype = ensemble_model_type)) +
  geom_line(aes(x= iteration, y = score, linetype = ensemble_model_type)) +
  geom_point(data = ensemble_scores_pap %>% 
         filter(grepl("*spearman_mean*", ensemble_model)) %>% 
         filter(score > 0.45) %>% 
           filter(!is.na(label)),
         aes(x= iteration, y = score, color = forcats::fct_inorder(label)), size = 2.5) +
   geom_point(data = ensemble_scores_pap %>% 
         filter(grepl("*rmse_mean*", ensemble_model)) %>% 
         filter(score <2) %>% 
         filter(!is.na(label)),
         aes(x= iteration, y = score/scal_fact, color = forcats::fct_inorder(label)), size = 2.5) +
  scale_color_manual(values = c("#307905",
                                "#00b8e6",
                                "#0000FF",
                                "#00d91d"),
                     name = "",
                     labels = c("Q.E.D",
                                "1 + Gregory Koytiger", 
                                "2 + AI Winter is Coming",
                                '3 + Oliver Labayle')) +
  scale_linetype_manual("",values=c("RMSE"=2,"Spearman"=1)) +
  scale_y_continuous(sec.axis = sec_axis(~.*scal_fact, name = "RMSE")) +
  theme_bw() +
  labs(x = "Number of Top Models", y = "Spearman Correlation") +
  theme(axis.text = element_text(size = 14),
        axis.title = element_text(size = 14))

```

plot the best vs gold standard where the 4th ensemble is the best: 

```{r echo=TRUE, message=FALSE, warning=FALSE}

best_ens_vs_gold <- mean_preds_sp %>% 
  left_join(gold) %>% 
  select(1:6, spearman_mean_ensemble_4, `pKd_[M]`) %>% 
  mutate(gold = `pKd_[M]`)

ggplot(data = best_ens_vs_gold) +
  geom_point(aes(x= gold, y= spearman_mean_ensemble_4)) +
  theme_bw() +
  labs(x = "Test Data (pKd)", y = "Best Spearman Ensemble (pKd)") +
  theme(axis.text = element_text(size = 12))
  
```

##RMSE

And now, we'll repeat the whole thing but with the other metric, RMSE. 

median: 

```{r echo=TRUE, message=FALSE, warning=FALSE}

best_rmse_by_team <- leaderboard %>%
  group_by(submitterId) %>%
  top_n(1, -rmse) %>%
  ungroup() %>%
  arrange(-rmse) %>%
  add_column(rank = group_indices(., rmse)) %>% 
  mutate(objectId = as.character(objectId))  

paths <- map_chr(best_rmse_by_team$id, get_path)
names(paths) <- best_rmse_by_team$objectId

preds <- pmap(.l = list(path = paths, renameColname = 'pKd_[M]_pred', newName = names(paths)), .f = challengescoring:::.read_and_rename) %>%
  purrr::reduce(left_join) %>%
  tidyr::gather(objectId, pred, -Compound_SMILES, -Compound_InchiKeys, -Compound_Name, -UniProt_Id, -Entrez_Gene_Symbol, -DiscoveRx_Gene_Symbol) %>% 
  left_join(select(best_rmse_by_team, objectId, rank))

median_preds_rm <- lapply(unique(preds$rank), function(i){
   colname <- paste0('rmse_median_ensemble_',i)
   foo <- preds %>%
     filter(rank <= i) %>% 
     group_by(Compound_SMILES, Compound_InchiKeys, Compound_Name, UniProt_Id, Entrez_Gene_Symbol,
              DiscoveRx_Gene_Symbol) %>% 
     summarize(!!colname := median(pred)) %>% 
     ungroup()
   foo
 }) %>% reduce(left_join)

median_test <- left_join(median_preds_rm, gold)

median_results_rmse <- apply(median_test %>% select(7:(ncol(median_test)-1),`pKd_[M]`), 2, rmse_py, 
                                 gold = median_test$`pKd_[M]`) %>% 
  as.data.frame() %>% 
  rownames_to_column("ensemble_model") %>% 
  filter(ensemble_model != "pKd_[M]") %>% 
  mutate(iteration = str_extract(ensemble_model, "[:digit:]+")) %>% 
  mutate(ensemble_model = str_extract(ensemble_model, "[:alpha:]+_[:alpha:]+_[:alpha:]+"))

```

ranked (weighted mean) RMSE:

```{r echo=TRUE, message=FALSE, warning=FALSE}

rank_preds_rm <- lapply(unique(preds$rank), function(i){
   colname <- paste0('rmse_rank_ensemble_',i)
   foo <- preds %>%
     filter(rank <= i) %>% 
     mutate(predrankweight = (pred*(55-rank))/sum((55-i):54)) %>% 
     group_by(Compound_SMILES, Compound_InchiKeys, Compound_Name, UniProt_Id, Entrez_Gene_Symbol,
              DiscoveRx_Gene_Symbol) %>% 
     summarize(!!colname := sum(predrankweight)) %>% 
     ungroup()
   foo
 }) %>% reduce(left_join)

rank_test <- left_join(rank_preds_rm, gold)

rank_results_rmse <- apply(rank_test %>% select(7:(ncol(rank_test)-1),`pKd_[M]`), 2, rmse_py, 
                                 gold = rank_test$`pKd_[M]`) %>% 
  as.data.frame() %>% 
  rownames_to_column("ensemble_model") %>% 
  filter(ensemble_model != "pKd_[M]") %>% 
  mutate(iteration = str_extract(ensemble_model, "[:digit:]+")) %>% 
  mutate(ensemble_model = str_extract(ensemble_model, "[:alpha:]+_[:alpha:]+_[:alpha:]+"))

```

mean:

```{r echo=TRUE, message=FALSE, warning=FALSE}

mean_preds_rm <- lapply(unique(preds$rank), function(i){
   colname <- paste0('rmse_mean_ensemble_',i)
   foo <- preds %>%
     filter(rank <= i) %>% 
     group_by(Compound_SMILES, Compound_InchiKeys, Compound_Name, UniProt_Id, Entrez_Gene_Symbol,
              DiscoveRx_Gene_Symbol) %>% 
     summarize(!!colname := mean(pred)) %>% 
     ungroup()
   foo
 }) %>% reduce(left_join)

mean_test <- left_join(mean_preds_rm, gold)

mean_results_rmse <- apply(mean_test %>% select(7:(ncol(mean_test)-1),`pKd_[M]`), 2, rmse_py, 
                                 gold = mean_test$`pKd_[M]`) %>% 
  as.data.frame() %>% 
  rownames_to_column("ensemble_model") %>% 
  filter(ensemble_model != "pKd_[M]") %>% 
  mutate(iteration = str_extract(ensemble_model, "[:digit:]+")) %>% 
  mutate(ensemble_model = str_extract(ensemble_model, "[:alpha:]+_[:alpha:]+_[:alpha:]+"))


```

plot it all:

```{r echo=TRUE, message=FALSE, warning=FALSE}

ensemble_scores <- bind_rows(median_results_rmse, mean_results_rmse, rank_results_rmse)  %>%  
  set_names(c("ensemble_model", "score", "iteration")) %>% 
  mutate(iteration = as.numeric(iteration)) %>% 
  mutate(label = case_when(iteration == 1 & ensemble_model == "rmse_rank_ensemble"  ~ "Gregory Koytiger",
                           iteration == 2 & ensemble_model == "rmse_rank_ensemble"  ~ "1 + AI Winter is Coming",
                           iteration == 3 & ensemble_model == "rmse_rank_ensemble" ~ "2 + DMIS_DK",
                           iteration == 4 & ensemble_model == "rmse_rank_ensemble" ~ "3 + ljwyc", 
                           iteration == 5 & ensemble_model == "rmse_rank_ensemble" ~ "4 + Q.E.D", 
                           iteration > 5 | ensemble_model != "rmse_rank_ensemble" ~ ""))

```

Plot  where RMSE <1

```{r}
ggplot(data = ensemble_scores %>% 
         filter(grepl("*rmse*", ensemble_model)) %>% 
         filter(score < 1)) +
  geom_line(aes(x= iteration, y = score, color = ensemble_model)) +
  ggrepel::geom_label_repel(aes(x= iteration, y = score, label = label), size = 3, segment.alpha = 0.25, alpha = 1, direction = "y", ylim =c(0.865,0.92), xlim = c(30,54), force = 20,arrow = grid::arrow(type = "open", length = unit(0.3, "lines"))) +
  scale_color_manual(values = c("#AA1155","#F8333C","#2B9EB3"),
                     name = "Method",
                     labels = c("Mean", "Median", "Rank-weighted")) +
  theme_bw() +
  labs(x = "# of Models", y = "RMSE") +
  theme(axis.text = element_text(size = 12))

```

Plot all no cutoff

```{r}
ggplot(data = ensemble_scores %>% 
         filter(grepl("*rmse*", ensemble_model))) +
  geom_line(aes(x= iteration, y = score, color = ensemble_model)) +
  scale_color_manual(values = c("#AA1155","#F8333C","#2B9EB3"),
                     name = "Method",
                     labels = c("Mean", "Median", "Rank-weighted")) +
  theme_bw() +
  labs(x = "# of Models", y = "RMSE") +
  theme(axis.text = element_text(size = 12))

```
plot the best vs gold standard, where the 5th ensemble is the best:

```{r echo=TRUE, message=FALSE, warning=FALSE}

best_ens_vs_gold <- mean_preds_rm %>% 
  left_join(gold) %>% 
  select(1:6, rmse_mean_ensemble_5, `pKd_[M]`) %>% 
  mutate(gold = `pKd_[M]`)

ggplot(data = best_ens_vs_gold) +
  geom_point(aes(x= gold, y= rmse_mean_ensemble_5)) +
  theme_bw() +
  labs(x = "Test Data (pKd)", y = "Best RMSE Ensemble (pKd)") +
  theme(axis.text = element_text(size = 12))
  
```

The following sections take a considerable amount of time to run so are set `eval=FALSE` by default. 

Then, we score all of these predictions using a bootstrap function from the `challengescoring` package. We'll calculate Bayes factors using the first 'ensemble' (i.e. the top method only)  as reference for "best" prediction to assess whether it's substantially different from its neighboring ensembles.

spearman:

```{r eval=FALSE, message=FALSE, warning=FALSE, eval=FALSE}

computeBayesFactorWhereRefIsNotBest <- function(bootstrapMetricMatrix,
                               refPredIndex,
                               invertBayes){

    M <- as.data.frame(bootstrapMetricMatrix - bootstrapMetricMatrix[,refPredIndex])
    K <- apply(M ,2, function(x) {
      k <- sum(x >= 0)/sum(x < 0)
      if(sum(x >= 0) > sum(x < 0)){
      return(k)
      }else{
      return(1/k)
      }
    })
    if(invertBayes == T){K <- 1/K}
    K[refPredIndex] <- 0

    return(K)
}


ens_spearman_rank_bs <- finalScoring(predictions = rank_preds_sp %>% select(-spearman_rank_ensemble_1),
                         predictionColname = NA,
                         predictionIds = colnames(rank_preds_sp %>% select(-spearman_rank_ensemble_1))[7:58],
                         goldStandard = gold,
                         goldStandardColname = 'pKd_[M]',
                         bestPrediction =  rank_preds_sp %>% select(1:6,spearman_rank_ensemble_1),
                         bestPredictionId = "spearman_rank_ensemble_1",
                         keyColumns = colnames(gold)[1:6],
                         doParallel = TRUE,
                         scoreFun = spearman_py,
                         largerIsBetter = T)

bayesredo <- computeBayesFactorWhereRefIsNotBest(ens_spearman_rank_bs$bootstrappedScores,
                                                 1, F)

tidy_bayes <- tibble('iteration' = colnames(ens_spearman_rank_bs$bootstrappedScores),
                         'bayes' = bayesredo)

tidy_res <- ens_spearman_rank_bs$bootstrappedScores %>%
  as.data.frame %>%
  tidyr::gather(iteration, bootstrappedScore) %>%
  left_join(tidy_bayes) %>%
  mutate(iteration = stringr::str_extract(iteration, "[:digit:]+") %>% as.numeric %>% as.integer) %>% 
  left_join(best_spearman_by_team, by = c("iteration" = "rank")) %>% 
  left_join(names_df) %>% 
  mutate(model = paste0(iteration-1," + ", participant))

ggplot(data = tidy_res) +
  geom_boxplot(aes(x = reorder(model, iteration, fun = mean) , y = bootstrappedScore,                     
                   color = cut(bayes, c(-1,0, 3, 5,Inf), include.lowest = T, ordered_result = T, right = T)), outlier.shape = NA)+
  scale_color_manual(values = c("#AA1155","#F8333C","#FCAB10","#2B9EB3"),
                     name = "Bayes Factor",
                     labels = c("Reference", "<3","3-5",">5")) +
  labs(x = "# of models", y = "Bootstrapped Spearman") +
  theme_bw() +
  theme(axis.text.x = element_text(size = 7, angle = 55, hjust = 1, vjust = 1))

```

RMSE:

```{r echo=TRUE, message=FALSE, warning=FALSE, eval=FALSE}


ens_rmse_rank_bs <- finalScoring(predictions = rank_preds_rm %>% select(-rmse_rank_ensemble_1),
                         predictionColname = NA,
                         predictionIds = colnames(rank_preds_rm %>% select(-rmse_rank_ensemble_1))[7:58],
                         goldStandard = gold,
                         goldStandardColname = 'pKd_[M]',
                         bestPrediction =  rank_preds_rm %>% select(1:6,rmse_rank_ensemble_1),
                         bestPredictionId = "rmse_rank_ensemble_1",
                         keyColumns = colnames(gold)[1:6],
                         doParallel = TRUE,
                         scoreFun = rmse_py,
                         largerIsBetter = T)

bayesredo <- computeBayesFactorWhereRefIsNotBest(ens_rmse_rank_bs$bootstrappedScores,
                                                 1, F)

tidy_bayes <- tibble('iteration' = colnames(ens_rmse_rank_bs$bootstrappedScores),
                         'bayes' = bayesredo)

tidy_res <- ens_rmse_rank_bs$bootstrappedScores %>%
  as.data.frame %>%
  tidyr::gather(iteration, bootstrappedScore) %>%
  left_join(tidy_bayes) %>%
  mutate(iteration = stringr::str_extract(iteration, "[:digit:]+") %>% as.numeric %>% as.integer) %>% 
  left_join(best_rmse_by_team, by = c("iteration" = "rank")) %>% 
  left_join(names_df) %>% 
  mutate(model = paste0(iteration-1," + ", participant))

ggplot(data = tidy_res) +
  geom_boxplot(aes(x = reorder(model, iteration, fun = mean) , y = bootstrappedScore,                     
                   color = cut(bayes, c(-1,0, 3, 5,Inf), include.lowest = T, ordered_result = T, right = T)), outlier.shape = NA)+
  scale_color_manual(values = c("#AA1155","#F8333C","#FCAB10","#2B9EB3"),
                     name = "Bayes Factor",
                     labels = c("Reference", "<3","3-5",">5")) +
  labs(x = "# of models", y = "Bootstrapped RMSE") +
  theme_bw() +
  theme(axis.text.x = element_text(size = 7, angle = 55, hjust = 1, vjust = 1))

```

```{r}
write_csv(mean_preds_sp,"spearman_mean_ensemble_models.csv")
write_csv(mean_preds_rm,"rmse_mean_ensemble_models.csv")
write_csv(median_preds_sp,"spearman_median_ensemble_models.csv")
write_csv(median_preds_rm,"rmse_median_ensemble_models.csv")
write_csv(rank_preds_sp,"spearman_rank_ensemble_models.csv")
write_csv(rank_preds_rm,"rmse_rank_ensemble_models.csv")

syn$store(synapse$File("spearman_mean_ensemble_models.csv", parentId = "syn18700959"))
syn$store(synapse$File("rmse_mean_ensemble_models.csv", parentId = "syn18700959"))
syn$store(synapse$File("spearman_median_ensemble_models.csv", parentId = "syn18700959"))
syn$store(synapse$File("rmse_median_ensemble_models.csv", parentId = "syn18700959"))
syn$store(synapse$File("spearman_rank_ensemble_models.csv", parentId = "syn18700959"))
syn$store(synapse$File("rmse_rank_ensemble_models.csv", parentId = "syn18700959"))

```


```{r}
sessionInfo()
```

