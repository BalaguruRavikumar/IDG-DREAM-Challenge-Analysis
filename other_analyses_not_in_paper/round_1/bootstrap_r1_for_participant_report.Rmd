---
title: "IDG-DREAM Round 1 Bootstrap Analysis"
author: "Robert Allaway"
date: "12/13/2018"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(comment=NA, fig.width=7, fig.height=7.5)

library(tidyverse)
library(reticulate)
library(pbapply)
use_python("/usr/local/bin/python2")
synapse <- import("synapseclient")
syn <- synapse$Synapse()
synutils <- synapse$utils
syn$login()
source_python('evaluation_metrics_python2.py')

seed<-15667962
set.seed(seed)

fv <- syn$tableQuery('SELECT * FROM syn17051994')$asDataFrame()

gold <- read.csv(syn$get("syn16809884")$path)

leaderboard <- syn$tableQuery('SELECT * FROM syn17054253')$asDataFrame() %>% 
  mutate(userId = as.character(userId))

names <- sapply(as.character(unique(leaderboard$userId)), function(x){
  foo<- syn$getUserProfile(x)
  name<- synutils$extract_user_name(foo)
}) %>% as.data.frame() %>% set_names("userName") %>% rownames_to_column("userId")

leaderboard <- leaderboard %>% left_join(names)
```
##Introduction 
Weâ€™ve completed an initial analysis of all of the prediction files that were submitted in Round 1. Specifically, we performed a bootstrap analysis of all of the prediction files to assess the stability of each submission with respect random subsets of the gold standard values. This analysis permitted the calculation of Bayes factors for all of these participants. We consider a submission with Bayes factor of 3 or less relative to the top-performing submission as an equally robust prediction as the top-performing submission.

##Methodology
Each prediction file was bootstrapped using a paired random sampling with replacement approach. Each prediction file was randomly sampled 10000 times, and each sampled set was scored to generate a distribution of bootstrapped scores per prediction file. For each bootstrapped set, we calculated Bayes factors relative to the top performer.

##Results

We plotted the boxplots summarizing the bootstrapped values for each metric using the leaderboard value superimposed on the distribution of the bootstrapped prediction. Bars are ranked highest to lowest performer (based on single leaderboard value for each metric). Orange points are the actual leaderboard value. We've colored each boxplot by Bayes factor, so any green colored boxes have a Bayes factor <3 and are treated as equally-performing predictions. Light blue is 3-5 (borderline equivalent), dark blue 5-20, and black >20. 

Each header below identifies the metric for that plot. The metrics are presented in the same order as the leaderboard and do not indicate preference for one metric over another. 


```{r message=FALSE, warning=FALSE, include=FALSE}
####################################################################
## General Post Challenge Utils for 
## January 2018  
## Andrew Lamb / Mike Mason (mainly Andrew)
####################################################################

library(plyr)
library(doMC)

# gs = gold standard (truth data) from validatoin, predictions = team 
# predictions, both assume each row is a sample, columns in gs could be multiple 
# this for scoreing like a binary value and its prethresholded value "time to 
# event", "event flag" 
# IMPORTANT THAT GS AND PREDICTIONS ARE IN SAME ORDER
# returns a vector of metric in order of teams
bootstrappingMetric <- function(goldStandardMatrix, predictionsMatrix, scoreFun, N = 1000, seed = seed, doParallel = T, ...) # N = number of samplings
{ 

    # matrix, columns are boostraps, rows are samples
    bsIndexMatrix <- matrix(1:nrow(goldStandardMatrix), nrow(goldStandardMatrix), N)
    bsIndexMatrix <- t(aaply(bsIndexMatrix, 2, sample, replace = T))# bootstrap indices
    
    registerDoMC(cores = detectCores()-1)
    gc()
    
    bsMetric   <- alply(.data     = bsIndexMatrix, 
                        .margins  = 2, 
                        .fun      = scoreFun, 
                        .parallel = doParallel, 
                        goldStandardMatrix, 
                        predictionsMatrix,
                        ...)
    # matrix, columns are teams, rows are bootstraps
    bsMetric <- do.call(rbind, bsMetric)
}

# this assumes the larger the  metric the better the prediction accuracy
# bayes facor (K) < a cut off, usually 3 or 5, will be tied with top performer. 
# Break ties w secondary metric

# computeBayesFactor <- function(bootstrapMetricMatrix, bestTeamIndex) 
# {                                                       
#   M <- as.data.frame((bootstrapMetricMatrix) - (bootstrapMetricMatrix[,bestTeamIndex]))
#   K        <- apply(M ,2, function(x) {sum(x <= 0)/sum(x > 0)})
#   K[bestTeamIndex] <- 0 
#   return(K)
# }

##I modified the function for use on RMSE - where lower values are better accuracy:
computeBayesFactor <- function(bootstrapMetricMatrix, bestTeamIndex, largerIsBetter = TRUE) 
{      
  if(largerIsBetter==TRUE){
    M <- as.data.frame(bootstrapMetricMatrix - bootstrapMetricMatrix[,bestTeamIndex])
    K <- apply(M ,2, function(x) {sum(x <= 0)/sum(x > 0)})
    K[bestTeamIndex] <- 0 
    return(K)
  }else{
    M <- as.data.frame(bootstrapMetricMatrix - (bootstrapMetricMatrix[,bestTeamIndex]))
    K <- apply(M ,2, function(x) {sum(-x <= 0)/sum(-x > 0)})
    K[bestTeamIndex] <- 0 
    return(K) 
  }
}
```

```{r message=FALSE, warning=FALSE, include=FALSE}
##munging data to work with post-challenge utils functions 

goldStandardMatrix <- gold %>% 
  arrange(Compound_SMILES, UniProt_Id, DiscoveRx_Gene_Symbol) %>%
  select(pKd_.M.) %>% 
  set_names(c("gold")) %>% 
  as.matrix()

predictionsMatrix <- pbapply(fv, 1, function(x){
  foo <- read.csv(syn$get(x['id'])$path) %>% 
    arrange(Compound_SMILES, UniProt_Id, DiscoveRx_Gene_Symbol) %>%
    select(pKd_.M._pred) %>% 
    set_names(c(x['id']))
}) %>% bind_cols() 

```

```{r message=FALSE, warning=FALSE, include=FALSE}
##wrappers for python functions to make them compatible with post challenge utils functions
spearman_r <- function(dataIndices, goldStandardMatrix, predictionsMatrix){
  
  pd.df <- as.data.frame(predictionsMatrix[dataIndices,])
  gs.df <- goldStandardMatrix[dataIndices,] %>% as.data.frame() %>% set_names("gold")
  gold <- gs.df$gold %>% np_array()
  
  spearman.s <- sapply(colnames(predictionsMatrix),function(x){
    spearman(gold, np_array(pd.df[[x]]))
  })
}

rmse_r <- function(dataIndices, goldStandardMatrix, predictionsMatrix){
  
  pd.df <- as.data.frame(predictionsMatrix[dataIndices,])
  gs.df <- goldStandardMatrix[dataIndices,] %>% as.data.frame() %>% set_names("gold")
  gold <- gs.df$gold %>% np_array()
  
  rmse.s <- sapply(colnames(predictionsMatrix),function(x){
    rmse(gold, np_array(pd.df[[x]]))
  })
}


auc_r <- function(dataIndices, goldStandardMatrix, predictionsMatrix){

  pd.df <- r_to_py(as.data.frame(predictionsMatrix[dataIndices,]))
  gs.df <- goldStandardMatrix[dataIndices,] %>% as.data.frame() %>% set_names("gold") %>% r_to_py()
  auc.s <- sapply(colnames(predictionsMatrix),function(x){
    average_AUC(gs.df$gold, pd.df[[x]])
  })
}

pearson_r <- function(dataIndices, goldStandardMatrix, predictionsMatrix){

  pd.df <- as.data.frame(predictionsMatrix[dataIndices,])
  gs.df <- goldStandardMatrix[dataIndices,] %>% as.data.frame() %>% set_names("gold")
  gold <- gs.df$gold %>% np_array()

  pearson.s <- sapply(colnames(predictionsMatrix),function(x){
    pearson(gold, np_array(pd.df[[x]]))
  })
}

ci_r <- function(dataIndices, goldStandardMatrix, predictionsMatrix){

  pd.df <- as.data.frame(predictionsMatrix[dataIndices,])
  gs.df <- goldStandardMatrix[dataIndices,] %>% as.data.frame() %>% set_names("gold")
  gold <- gs.df$gold %>% np_array()

  ci.s <- sapply(colnames(predictionsMatrix),function(x){
    ci(gold, np_array(pd.df[[x]]))
  })
}

f1_r <- function(dataIndices, goldStandardMatrix, predictionsMatrix){

  pd.df <- r_to_py(as.data.frame(predictionsMatrix[dataIndices,]))
  gs.df <- goldStandardMatrix[dataIndices,] %>% as.data.frame() %>% set_names("gold") %>% r_to_py()
  f1.s <- sapply(colnames(predictionsMatrix),function(x){
    f1(gs.df$gold, pd.df[[x]])
  })
}

```

```{r message=FALSE, warning=FALSE, include=FALSE}
# bootstrapMetricMatrix_rmse <- bootstrappingMetric(goldStandardMatrix = goldStandardMatrix, predictionsMatrix = predictionsMatrix, scoreFun = rmse_r, N = 10000)

bootstrapMetricMatrix_rmse <- syn$get("syn17083375")$path %>% read.csv() %>% as.matrix()

bootstrapMetricMatrix_rmse <- round(bootstrapMetricMatrix_rmse, 5)

ranked_submissions <- fv %>% select(id, submissionId) %>% set_names(c("id", "objectId")) %>% left_join(leaderboard) %>% select(id, rmse) %>% arrange(desc(rmse))

##rmse best submission is syn17053970, 87th col in bootstrapMetricMatrix
bf_rmse <- computeBayesFactor(bootstrapMetricMatrix_rmse, 87, largerIsBetter = F) %>% as.data.frame() %>% set_names("bayes_factor_rmse") %>% rownames_to_column("id")
```

###RMSE (scores < 5) 
####Very high RMSE values  were removed to expand the plot
```{r echo=FALSE, message=FALSE, warning=FALSE}
bs_rmse_plotting_data <- bootstrapMetricMatrix_rmse %>%
  as.data.frame() %>%
  tidyr::gather(key="id",value="bootstrap_rmse") %>%
  left_join(fv) %>%
  mutate(objectId=submissionId) %>%
  mutate(userId = as.character(userId)) %>%
  left_join(leaderboard) %>%
  mutate(label = paste(objectId, userName, sep = "_")) %>%
  left_join(bf_rmse) %>% 
  group_by(userName) %>% 
  top_n(1, -rmse) %>%
  top_n(1, objectId) %>% #this selects most recent submission if there are multiple identically scored ones per group
  ungroup() %>% 
  filter(rmse < 5)

bs_rmse_plotting_data$label <- factor(bs_rmse_plotting_data$label, levels = unique(bs_rmse_plotting_data$label[order(-bs_rmse_plotting_data$rmse)]))

p<-ggplot() +
  geom_boxplot(data = bs_rmse_plotting_data, 
               aes(x=label, y=bootstrap_rmse,
                   color = cut(bayes_factor_rmse, c(-Inf, 3, 5, 20, Inf))), fill = "#FFFFFF", outlier.shape = NA) +
  coord_flip() +
  scale_color_manual(values = c("#499F68","#087F8C", "#1F5673","#46494C"),
                     name = "Bayes Factor",
                     labels = c("<3","3-5","5-20",">20")) +
   geom_point(data = bs_rmse_plotting_data %>%
                     select(label, rmse) %>% 
                    distinct(),
              aes(x=label, y=rmse), color = "#F18F01", shape = "circle small", size = 2) +
  labs(x = "Submission & User", y = "Bootstrapped RMSE") +
  theme_minimal()+
  theme(axis.text.y = element_text(size = 8)) 

p

```


###log(RMSE) (all scores)
```{r echo=FALSE, message=FALSE, warning=FALSE}
bs_rmse_plotting_data <- bootstrapMetricMatrix_rmse %>%
  as.data.frame() %>%
  tidyr::gather(key="id",value="bootstrap_rmse") %>%
  left_join(fv) %>%
  mutate(objectId=submissionId) %>%
  mutate(userId = as.character(userId)) %>%
  left_join(leaderboard) %>%
  mutate(label = paste(objectId, userName, sep = "_")) %>%
  left_join(bf_rmse) %>% 
  group_by(userName) %>% 
  top_n(1, -rmse) %>%
  top_n(1, objectId) %>% #this selects most recent submission if there are multiple identically scored ones per group
  ungroup()

bs_rmse_plotting_data$label <- factor(bs_rmse_plotting_data$label, levels = unique(bs_rmse_plotting_data$label[order(-bs_rmse_plotting_data$rmse)]))

p<-ggplot() +
  geom_boxplot(data = bs_rmse_plotting_data, 
               aes(x=label, y=log(bootstrap_rmse),
                   color = cut(bayes_factor_rmse, c(-Inf, 3, 5, 20, Inf))), fill = "#FFFFFF", outlier.shape = NA) +
  coord_flip() +
  scale_color_manual(values = c("#499F68","#087F8C", "#1F5673","#46494C"),
                     name = "Bayes Factor",
                     labels = c("<3","3-5","5-20",">20")) +
   geom_point(data = bs_rmse_plotting_data %>%
                     select(label, rmse) %>% 
                    distinct(),
              aes(x=label, y=log(rmse)), color = "#F18F01", shape = "circle small", size = 2) +
  labs(x = "Submission & User", y = "log(Bootstrapped RMSE)") +
  theme_minimal()+
  theme(axis.text.y = element_text(size = 8)) 

p

```

```{r message=FALSE, warning=FALSE, include=FALSE}
# bootstrapMetricMatrix_pearson <- bootstrappingMetric(goldStandardMatrix = goldStandardMatrix, predictionsMatrix = predictionsMatrix, scoreFun = pearson_r, N = 10000) 

bootstrapMetricMatrix_pearson <- syn$get("syn17089700")$path %>% read.csv() %>% as.matrix()

bootstrapMetricMatrix_pearson <- round(bootstrapMetricMatrix_pearson, 5)

ranked_submissions <- fv %>% select(id, submissionId) %>% set_names(c("id", "objectId")) %>% left_join(leaderboard) %>% select(id, pearson) %>% arrange(desc(pearson))

##pearson best submission is syn17053907, 27th col in bootstrapMetricMatrix

#bootstrapMetricMatrix_pearson <- syn$get("syn17083374")$path %>% read.csv() %>% as.matrix()

##this is tiebreaker for best submission Spearman 27th col in bootstrapMetricMatrix
bf_pearson <- computeBayesFactor(bootstrapMetricMatrix_pearson, 27) %>% as.data.frame() %>% set_names("bayes_factor_pearson") %>% rownames_to_column("id")


```

###Pearson correlation

```{r echo=FALSE, message=FALSE, warning=FALSE}
bs_pearson_plotting_data <- bootstrapMetricMatrix_pearson %>%
   as.data.frame() %>%
   tidyr::gather(key="id",value="bootstrap_pearson") %>%
   left_join(fv) %>%
   mutate(objectId=submissionId) %>%
   mutate(userId = as.character(userId)) %>%
   left_join(leaderboard) %>%
   mutate(label = paste(objectId, userName, sep = "_")) %>%
   left_join(bf_pearson) %>% 
  group_by(userName) %>% 
  top_n(1, pearson) %>% 
  top_n(1, objectId) %>% #this selects most recent submission if there are multiple identically scored ones per group
  ungroup()

##have to hard-code 9682710 as a BF of 0, because bootstrapped data is identical to same participant's other submission (that is the basis for this calculation)

bs_pearson_plotting_data <- bs_pearson_plotting_data %>% 
  mutate(bayes_factor_pearson = case_when(label == "9682710_Accutar" ~ 0, label != "9682710_Accutar" ~ bayes_factor_pearson))

bs_pearson_plotting_data$label <- factor(bs_pearson_plotting_data$label, levels = unique(bs_pearson_plotting_data$label[order(bs_pearson_plotting_data$pearson)]))

p<-ggplot() +
  geom_boxplot(data = bs_pearson_plotting_data, 
               aes(x=label, y=bootstrap_pearson,
                   color = cut(bayes_factor_pearson, c(-Inf, 3, 5, 20, Inf))), fill = "#FFFFFF", outlier.shape = NA) +
  coord_flip() +
  scale_color_manual(values = c("#499F68","#087F8C", "#1F5673","#46494C"),
                     name = "Bayes Factor",
                     labels = c("<3","3-5","5-20",">20")) +
   geom_point(data = bs_pearson_plotting_data %>% 
                     select(label, pearson) %>% 
                    distinct(),
              aes(x=label, y=pearson), color = "#F18F01", shape = "circle small", size = 2) +
  labs(x = "Submission & User", y = "Bootstrapped Pearson") +
  theme_minimal() +
  theme(axis.text.y = element_text(size = 8))

p

```

```{r message=FALSE, warning=FALSE, include=FALSE}
# bootstrapMetricMatrix_spearman <- bootstrappingMetric(goldStandardMatrix = goldStandardMatrix, predictionsMatrix = predictionsMatrix, scoreFun = spearman_r, N = 10000)

bootstrapMetricMatrix_spearman <- syn$get("syn17083376")$path %>% read.csv() %>% as.matrix()

bootstrapMetricMatrix_spearman <- round(bootstrapMetricMatrix_spearman, 5)

ranked_submissions <- fv %>% select(id, submissionId) %>% set_names(c("id", "objectId")) %>% left_join(leaderboard) %>% select(id, spearman) %>% arrange(desc(spearman)) 

##spearman best submission is syn17053907, 27th col in bootstrapMetricMatrix

bf_spearman <- computeBayesFactor(bootstrapMetricMatrix_spearman, 27) %>% as.data.frame() %>% set_names("bayes_factor_spearman") %>% rownames_to_column("id")
```

###Spearman correlation

```{r echo=FALSE, message=FALSE, warning=FALSE}
bs_spearman_plotting_data <- bootstrapMetricMatrix_spearman %>%
  as.data.frame() %>%
  tidyr::gather(key="id",value="bootstrap_spearman") %>%
  left_join(fv) %>%
  mutate(objectId=submissionId) %>%
  mutate(userId = as.character(userId)) %>%
  left_join(leaderboard) %>%
  mutate(label = paste(objectId, userName, sep = "_")) %>%
  left_join(bf_spearman) %>% 
  group_by(userName) %>% 
  top_n(1, spearman) %>% 
  top_n(1, objectId) %>% #this selects most recent submission if there are multiple identically scored ones per group
  ungroup()

##have to hard-code 9682710 as a BF of 0, because bootstrapped data is identical to same participant's other submission (that is the basis for this calculation)

bs_spearman_plotting_data <- bs_spearman_plotting_data %>% 
  mutate(bayes_factor_spearman = case_when(label == "9682710_Accutar" ~ 0, label != "9682710_Accutar" ~ bayes_factor_spearman))

bs_spearman_plotting_data$label <- factor(bs_spearman_plotting_data$label, levels = unique(bs_spearman_plotting_data$label[order(bs_spearman_plotting_data$spearman)]))

p<-ggplot() +
  geom_boxplot(data = bs_spearman_plotting_data, 
               aes(x=label, y=bootstrap_spearman,
                   color = cut(bayes_factor_spearman, c(-Inf, 3, 5, 20, Inf))), fill = "#FFFFFF", outlier.shape = NA) +
  coord_flip() +
  scale_color_manual(values = c("#499F68","#087F8C", "#1F5673","#46494C"),
                     name = "Bayes Factor",
                     labels = c("<3","3-5","5-20",">20")) +
   geom_point(data = bs_spearman_plotting_data %>% 
                     select(label, spearman) %>% 
                    distinct(),
              aes(x=label, y=spearman), color = "#F18F01", shape = "circle small", size = 2) +
  labs(x = "Submission & User", y = "Bootstrapped Spearman") +
  theme_minimal() +
  theme(axis.text.y = element_text(size = 8))

p

```


```{r message=FALSE, warning=FALSE, include=FALSE}
# bootstrapMetricMatrix_f1 <- bootstrappingMetric(goldStandardMatrix = goldStandardMatrix, predictionsMatrix = predictionsMatrix, scoreFun = f1_r, N = 10000) 

bootstrapMetricMatrix_f1 <- syn$get("syn17089702")$path %>% read.csv() %>% as.matrix()

bootstrapMetricMatrix_f1 <- round(bootstrapMetricMatrix_f1, 5)

ranked_submissions <- fv %>% select(id, submissionId) %>% set_names(c("id", "objectId")) %>% left_join(leaderboard) %>% select(id, f1) %>% arrange(desc(f1))

##f1 best submission is syn17053954, 71th col in bootstrapMetricMatrix

#bootstrapMetricMatrix_f1 <- syn$get("syn17083374")$path %>% read.csv() %>% as.matrix()

bf_f1 <- computeBayesFactor(bootstrapMetricMatrix_f1, 71) %>% as.data.frame() %>% set_names("bayes_factor_f1") %>% rownames_to_column("id")


```

###F1

```{r echo=FALSE, message=FALSE, warning=FALSE}
bs_f1_plotting_data <- bootstrapMetricMatrix_f1 %>%
   as.data.frame() %>%
   tidyr::gather(key="id",value="bootstrap_f1") %>%
   left_join(fv) %>%
   mutate(objectId=submissionId) %>%
   mutate(userId = as.character(userId)) %>%
   left_join(leaderboard) %>%
   mutate(label = paste(objectId, userName, sep = "_")) %>%
   left_join(bf_f1)%>% 
  group_by(userName) %>% 
  top_n(1, f1) %>% 
  top_n(1, objectId) %>% #this selects most recent submission if there are multiple identically scored ones per group
  ungroup()

bs_f1_plotting_data$label <- factor(bs_f1_plotting_data$label, levels = unique(bs_f1_plotting_data$label[order(bs_f1_plotting_data$f1)]))

p<-ggplot() +
  geom_boxplot(data = bs_f1_plotting_data, 
               aes(x=label, y=bootstrap_f1,
                   color = cut(bayes_factor_f1, c(-Inf, 3, 5, 20, Inf))), fill = "#FFFFFF", outlier.shape = NA) +
  coord_flip() +
  scale_color_manual(values = c("#499F68","#087F8C", "#1F5673","#46494C"),
                     name = "Bayes Factor",
                     labels = c("<3","3-5","5-20",">20")) +
   geom_point(data = bs_f1_plotting_data %>%
                     select(label, f1) %>% 
                    distinct(),
              aes(x=label, y=f1), color = "#F18F01", shape = "circle small", size = 2) +
  labs(x = "Submission & User", y = "Bootstrapped F1") +
  theme_minimal() +
  theme(axis.text.y = element_text(size = 8))

p

```


```{r message=FALSE, warning=FALSE, include=FALSE}
# bootstrapMetricMatrix_ci <- bootstrappingMetric(goldStandardMatrix = goldStandardMatrix, predictionsMatrix = predictionsMatrix, scoreFun = ci_r, N = 10000) 

bootstrapMetricMatrix_ci <- syn$get("syn17090799")$path %>% read.csv() %>% as.matrix()

bootstrapMetricMatrix_ci <- round(bootstrapMetricMatrix_ci, 5)

ranked_submissions <- fv %>% select(id, submissionId) %>% set_names(c("id", "objectId")) %>% left_join(leaderboard) %>% select(id, ci) %>% arrange(desc(ci))

##ci best submission is syn17053907, 27th col in bootstrapMetricMatrix

#bootstrapMetricMatrix_ci <- syn$get("syn17083374")$path %>% read.csv() %>% as.matrix()

bf_ci <- computeBayesFactor(bootstrapMetricMatrix_ci, 27) %>% as.data.frame() %>% set_names("bayes_factor_ci") %>% rownames_to_column("id")


```

###CI

```{r echo=FALSE, message=FALSE, warning=FALSE}
bs_ci_plotting_data <- bootstrapMetricMatrix_ci %>%
   as.data.frame() %>%
   tidyr::gather(key="id",value="bootstrap_ci") %>%
   left_join(fv) %>%
   mutate(objectId=submissionId) %>%
   mutate(userId = as.character(userId)) %>%
   left_join(leaderboard) %>%
   mutate(label = paste(objectId, userName, sep = "_")) %>%
   left_join(bf_ci) %>% 
  group_by(userName) %>% 
  top_n(1, ci) %>% 
  top_n(1, objectId) %>% #this selects most recent submission if there are multiple identically scored ones per group
  ungroup()

##have to hard-code 9682710 as a BF of 0, because bootstrapped data is identical to same participant's other submission (that is the basis for this calculation)

bs_ci_plotting_data <- bs_ci_plotting_data %>% 
  mutate(bayes_factor_ci = case_when(label == "9682710_Accutar" ~ 0, label != "9682710_Accutar" ~ bayes_factor_ci))

bs_ci_plotting_data$label <- factor(bs_ci_plotting_data$label, levels = unique(bs_ci_plotting_data$label[order(bs_ci_plotting_data$ci)]))

p<-ggplot() +
  geom_boxplot(data = bs_ci_plotting_data, 
               aes(x=label, y=bootstrap_ci,
                   color = cut(bayes_factor_ci, c(-Inf, 3, 5, 20, Inf))), fill = "#FFFFFF", outlier.shape = NA) +
  coord_flip() +
  scale_color_manual(values = c("#499F68","#087F8C", "#1F5673","#46494C"),
                     name = "Bayes Factor",
                     labels = c("<3","3-5","5-20",">20")) +
   geom_point(data = bs_ci_plotting_data %>% 
                     select(label, ci) %>% 
                    distinct(),
              aes(x=label, y=ci), color = "#F18F01", shape = "circle small", size = 2) +
  labs(x = "Submission & User", y = "Bootstrapped CI") +
  theme_minimal() +
  theme(axis.text.y = element_text(size = 8))

p

```

```{r message=FALSE, warning=FALSE, include=FALSE}
# bootstrapMetricMatrix_auc <- bootstrappingMetric(goldStandardMatrix = goldStandardMatrix, predictionsMatrix = predictionsMatrix, scoreFun = auc_r, N = 10000)

bootstrapMetricMatrix_auc <- syn$get("syn17083374")$path %>% read.csv() %>% as.matrix()

bootstrapMetricMatrix_auc <- round(bootstrapMetricMatrix_auc, 5)

ranked_submissions <- fv %>% select(id, submissionId) %>% set_names(c("id", "objectId")) %>% left_join(leaderboard) %>% select(id, average_AUC) %>% arrange(desc(average_AUC))

##best performer for AUC is 27th col in bootstrapMetricMatrix
bf_auc <- computeBayesFactor(bootstrapMetricMatrix_auc, 27) %>% as.data.frame() %>% set_names("bayes_factor_auc") %>% rownames_to_column("id")
```

###Average AUC

```{r echo=FALSE, message=FALSE, warning=FALSE}
bs_auc_plotting_data <- bootstrapMetricMatrix_auc %>%
   as.data.frame() %>%
   tidyr::gather(key="id",value="bootstrap_auc") %>%
   left_join(fv) %>%
   mutate(objectId=submissionId) %>%
   mutate(userId = as.character(userId)) %>%
   left_join(leaderboard) %>%
   mutate(label = paste(objectId, userName, sep = "_")) %>%
   left_join(bf_auc) %>% 
  group_by(userName) %>% 
  top_n(1, average_AUC) %>% 
  top_n(1, objectId) %>% #this selects most recent submission if there are multiple identically scored ones per group
  ungroup()

bs_auc_plotting_data$label <- factor(bs_auc_plotting_data$label, levels = unique(bs_auc_plotting_data$label[order(bs_auc_plotting_data$average_AUC)]))

##have to hard-code 9682710 as a BF of 0, because bootstrapped data is identical to same participant's other submission (that is the basis for this calculation)

bs_auc_plotting_data <- bs_auc_plotting_data %>% 
  mutate(bayes_factor_auc = case_when(label == "9682710_Accutar" ~ 0, label != "9682710_Accutar" ~ bayes_factor_auc))

p<-ggplot() +
  geom_boxplot(data = bs_auc_plotting_data, 
               aes(x=label, y=bootstrap_auc,
                   color = cut(bayes_factor_auc, c(-Inf, 3, 5, 20, Inf))), fill = "#FFFFFF", outlier.shape = NA) +
  coord_flip() +
  scale_color_manual(values = c("#499F68","#087F8C", "#1F5673","#46494C"),
                     name = "Bayes Factor",
                     labels = c("<3","3-5","5-20",">20")) +
   geom_point(data = bs_auc_plotting_data %>% 
                     select(label, average_AUC) %>% 
                    distinct(),
              aes(x=label, y=average_AUC), color = "#F18F01", shape = "circle small", size = 2) +
  labs(x = "Submission & User", y = "Bootstrapped AUC") +
  theme_minimal() +
  theme(axis.text.y = element_text(size = 8))

p

```
```{r message=FALSE, warning=FALSE, include=FALSE}
#for reuploading bootstrapped data...

this.file = 'https://raw.githubusercontent.com/Sage-Bionetworks/IDG-DREAM-Challenge-Analysis/master/round_1/bootstrap_r1.Rmd'

# write.csv(bootstrapMetricMatrix_auc,"bootstrapped_auc_r1.csv", row.names = F)
# syn$store(synapse$File('bootstrapped_auc_r1.csv', parentId = 'syn17083205'), executed = this.file, used = c("syn17051994", "syn16809884", "syn17054253", fv$id))
# 
# write.csv(bootstrapMetricMatrix_rmse,"bootstrapped_rmse_r1.csv", row.names = F)
# syn$store(synapse$File('bootstrapped_rmse_r1.csv', parentId = 'syn17083205'), executed = this.file, used = c("syn17051994", "syn16809884", "syn17054253", fv$id))
# 
# write.csv(bootstrapMetricMatrix_spearman,"bootstrapped_spearman_r1.csv", row.names = F)
# syn$store(synapse$File('bootstrapped_spearman_r1.csv', parentId = 'syn17083205'), executed = this.file, used = c("syn17051994", "syn16809884", "syn17054253", fv$id))
# 
# write.csv(bootstrapMetricMatrix_ci,"bootstrapped_ci_r1.csv", row.names = F)
# syn$store(synapse$File('bootstrapped_ci_r1.csv', parentId = 'syn17083205'), executed = this.file, used = c("syn17051994", "syn16809884", "syn17054253", fv$id))
# 
# write.csv(bootstrapMetricMatrix_pearson,"bootstrapped_pearson_r1.csv", row.names = F)
# syn$store(synapse$File('bootstrapped_pearson_r1.csv', parentId = 'syn17083205'), executed = this.file, used = c("syn17051994", "syn16809884", "syn17054253", fv$id))
# 
# write.csv(bootstrapMetricMatrix_f1,"bootstrapped_f1_r1.csv", row.names = F)
# syn$store(synapse$File('bootstrapped_f1_r1.csv', parentId = 'syn17083205'), executed = this.file, used = c("syn17051994", "syn16809884", "syn17054253", fv$id))

```


